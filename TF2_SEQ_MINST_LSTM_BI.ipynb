{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TF2_SEQ_MINST_LSTM_BI.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNQ36Z0ZJfddXM4/Vl7QzQK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"hLx425Qx3TIV","executionInfo":{"status":"ok","timestamp":1608992151906,"user_tz":-480,"elapsed":5115,"user":{"displayName":"Ethan Jiang","photoUrl":"","userId":"03869454943297393300"}}},"source":["'''\n","RNN for MNIST digits classification\n","97.7% test accuracy in 20epochs\n","75K adjustable parameters\n","input -> 256 -> 10\n","\n","https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras\n","'''\n","\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import numpy as np\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation, SimpleRNN, LSTM, Input, Bidirectional\n","from tensorflow.keras.utils import to_categorical, plot_model\n","from tensorflow.keras.datasets import mnist\n","\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"5JRSesJW8GzA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608992153340,"user_tz":-480,"elapsed":6537,"user":{"displayName":"Ethan Jiang","photoUrl":"","userId":"03869454943297393300"}},"outputId":"778aeeab-a79c-4cb5-d3ef-669ae129f573"},"source":["!python --version\n","!pip list | grep tensorflow"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Python 3.6.9\n","tensorflow                    2.4.0          \n","tensorflow-addons             0.8.3          \n","tensorflow-datasets           4.0.1          \n","tensorflow-estimator          2.4.0          \n","tensorflow-gcs-config         2.4.0          \n","tensorflow-hub                0.10.0         \n","tensorflow-metadata           0.26.0         \n","tensorflow-privacy            0.2.2          \n","tensorflow-probability        0.11.0         \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GogQo3v66lCo"},"source":["## Clean Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DFNqdsxO5VMD","executionInfo":{"status":"ok","timestamp":1608992153341,"user_tz":-480,"elapsed":6532,"user":{"displayName":"Ethan Jiang","photoUrl":"","userId":"03869454943297393300"}},"outputId":"d01a08b3-00c0-472c-aa9d-85d3df01636d"},"source":["# load mnist dataset\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# compute the number of labels\n","num_labels = len(np.unique(y_train))\n","\n","# convert to one-hot vector\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","# resize and normalize\n","#image_size = x_train.shape[1]\n","#print(x_train.shape)\n","\n","x_train = np.reshape(x_train,[x_train.shape[0], -1, 1])\n","x_test = np.reshape(x_test,[x_test.shape[0], -1, 1])\n","\n","x_train = x_train.astype('float32') / 255\n","x_test = x_test.astype('float32') / 255\n","\n","print(\"x_train\", x_train.shape)\n","print(\"y_train\", y_train.shape)\n","\n","print(\"x_test\", x_test.shape)\n","print(\"y_test\", y_test.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","x_train (60000, 784, 1)\n","y_train (60000, 10)\n","x_test (10000, 784, 1)\n","y_test (10000, 10)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GvvYEJ6M6oDK"},"source":["## Setup Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cxZGE7JU5JXy","executionInfo":{"status":"ok","timestamp":1608992157449,"user_tz":-480,"elapsed":10634,"user":{"displayName":"Ethan Jiang","photoUrl":"","userId":"03869454943297393300"}},"outputId":"76ce8ea1-907a-436a-d15b-55a14920fb98"},"source":["# network parameters\n","input_shape = (x_train.shape[1:])\n","batch_size = 128\n","units = 100\n","dropout = 0.00\n","\n","# model is RNN with 256 units, input is 28-dim vector 28 timesteps\n","model = Sequential()\n","model.add(Input(input_shape, name=\"input\"))\n","model.add(Bidirectional(LSTM(units=units,\n","                    dropout=dropout, name=\"ltsm\" )))\n","                    #input_shape=input_shape))\n","model.add(Dense(num_labels, name=\"dense\"))\n","model.add(Activation('softmax', name=\"activate\"))\n","model.summary()\n","print(\"units\", units)\n","print(\"input_shape\", input_shape)\n","print(\"num_labels\", num_labels)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bidirectional (Bidirectional (None, 200)               81600     \n","_________________________________________________________________\n","dense (Dense)                (None, 10)                2010      \n","_________________________________________________________________\n","activate (Activation)        (None, 10)                0         \n","=================================================================\n","Total params: 83,610\n","Trainable params: 83,610\n","Non-trainable params: 0\n","_________________________________________________________________\n","units 100\n","input_shape (784, 1)\n","num_labels 10\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W2SW3Fvr6rqe"},"source":["## Model compile and fit (train)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ujA9ACYy5PLm","outputId":"77971a69-c253-4134-f1cd-664d2f42340b"},"source":["# enable this if pydot can be installed\n","# pip install pydot\n","#plot_model(model, to_file='rnn-mnist.png', show_shapes=True)\n","\n","# loss function for one-hot vector\n","# use of sgd optimizer\n","# accuracy is good metric for classification tasks\n","\n","from keras.optimizers import RMSprop\n","\n","learning_rate = 1e-3\n","rmsprop = RMSprop(lr=learning_rate)\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer= rmsprop,\n","              metrics=['accuracy'])\n","\n","#model.compile(loss='categorical_crossentropy',\n","#              optimizer='sgd',\n","#              metrics=['accuracy'])\n","# train the network\n","\n","model.fit(x_train, y_train, \n","          epochs=200, \n","          batch_size=batch_size,\n","          validation_data=(x_test, y_test))\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","469/469 [==============================] - 45s 83ms/step - loss: 2.2912 - accuracy: 0.1301 - val_loss: 2.3129 - val_accuracy: 0.1009\n","Epoch 2/200\n","469/469 [==============================] - 38s 81ms/step - loss: 2.3070 - accuracy: 0.1082 - val_loss: 2.3023 - val_accuracy: 0.1135\n","Epoch 3/200\n","469/469 [==============================] - 38s 81ms/step - loss: 2.3015 - accuracy: 0.1080 - val_loss: 2.1965 - val_accuracy: 0.1814\n","Epoch 4/200\n","469/469 [==============================] - 38s 82ms/step - loss: 2.2080 - accuracy: 0.1786 - val_loss: 2.2129 - val_accuracy: 0.1830\n","Epoch 5/200\n","469/469 [==============================] - 38s 82ms/step - loss: 2.0843 - accuracy: 0.2378 - val_loss: 2.2500 - val_accuracy: 0.1801\n","Epoch 6/200\n","469/469 [==============================] - 39s 82ms/step - loss: 2.0671 - accuracy: 0.2256 - val_loss: 2.3244 - val_accuracy: 0.1135\n","Epoch 7/200\n","469/469 [==============================] - 38s 82ms/step - loss: 2.2765 - accuracy: 0.1388 - val_loss: 2.5537 - val_accuracy: 0.1053\n","Epoch 8/200\n","469/469 [==============================] - 39s 82ms/step - loss: 2.2263 - accuracy: 0.1692 - val_loss: 1.9542 - val_accuracy: 0.2149\n","Epoch 9/200\n","469/469 [==============================] - 39s 82ms/step - loss: 1.9332 - accuracy: 0.2547 - val_loss: 2.3502 - val_accuracy: 0.1354\n","Epoch 10/200\n","469/469 [==============================] - 38s 82ms/step - loss: 2.3048 - accuracy: 0.1131 - val_loss: 1.8325 - val_accuracy: 0.3223\n","Epoch 11/200\n","469/469 [==============================] - 38s 82ms/step - loss: 1.9367 - accuracy: 0.3002 - val_loss: 2.3116 - val_accuracy: 0.1028\n","Epoch 12/200\n","469/469 [==============================] - 38s 81ms/step - loss: 2.2686 - accuracy: 0.1237 - val_loss: 1.9130 - val_accuracy: 0.3112\n","Epoch 13/200\n","469/469 [==============================] - 38s 81ms/step - loss: 1.6969 - accuracy: 0.3625 - val_loss: 1.8900 - val_accuracy: 0.3353\n","Epoch 14/200\n","469/469 [==============================] - 38s 82ms/step - loss: 1.6202 - accuracy: 0.3954 - val_loss: 1.4520 - val_accuracy: 0.4730\n","Epoch 15/200\n","469/469 [==============================] - 38s 81ms/step - loss: 1.4859 - accuracy: 0.4358 - val_loss: 1.3576 - val_accuracy: 0.4775\n","Epoch 16/200\n","469/469 [==============================] - 38s 81ms/step - loss: 1.3009 - accuracy: 0.5274 - val_loss: 1.0354 - val_accuracy: 0.6340\n","Epoch 17/200\n","469/469 [==============================] - 38s 80ms/step - loss: 1.0540 - accuracy: 0.6370 - val_loss: 0.8640 - val_accuracy: 0.7056\n","Epoch 18/200\n","469/469 [==============================] - 38s 81ms/step - loss: 0.8801 - accuracy: 0.7039 - val_loss: 0.6706 - val_accuracy: 0.7714\n","Epoch 19/200\n","469/469 [==============================] - 38s 80ms/step - loss: 0.7337 - accuracy: 0.7480 - val_loss: 0.5897 - val_accuracy: 0.7903\n","Epoch 20/200\n","469/469 [==============================] - 38s 80ms/step - loss: 0.6386 - accuracy: 0.7811 - val_loss: 0.5503 - val_accuracy: 0.8045\n","Epoch 21/200\n","469/469 [==============================] - 38s 81ms/step - loss: 0.5761 - accuracy: 0.7958 - val_loss: 0.4894 - val_accuracy: 0.8254\n","Epoch 22/200\n","469/469 [==============================] - 38s 81ms/step - loss: 0.5025 - accuracy: 0.8181 - val_loss: 0.4021 - val_accuracy: 0.8495\n","Epoch 23/200\n","469/469 [==============================] - 38s 81ms/step - loss: 0.4406 - accuracy: 0.8400 - val_loss: 0.4304 - val_accuracy: 0.8388\n","Epoch 24/200\n","469/469 [==============================] - 38s 81ms/step - loss: 0.3983 - accuracy: 0.8523 - val_loss: 0.3475 - val_accuracy: 0.8697\n","Epoch 25/200\n","469/469 [==============================] - 38s 81ms/step - loss: 0.3690 - accuracy: 0.8642 - val_loss: 0.3502 - val_accuracy: 0.8707\n","Epoch 26/200\n","469/469 [==============================] - 39s 83ms/step - loss: 0.3325 - accuracy: 0.8772 - val_loss: 0.2902 - val_accuracy: 0.8941\n","Epoch 27/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.3113 - accuracy: 0.8861 - val_loss: 0.2639 - val_accuracy: 0.9056\n","Epoch 28/200\n","469/469 [==============================] - 39s 83ms/step - loss: 0.2907 - accuracy: 0.8945 - val_loss: 0.3355 - val_accuracy: 0.8789\n","Epoch 29/200\n","469/469 [==============================] - 39s 83ms/step - loss: 0.2734 - accuracy: 0.9037 - val_loss: 0.2422 - val_accuracy: 0.9145\n","Epoch 30/200\n","469/469 [==============================] - 39s 83ms/step - loss: 0.2494 - accuracy: 0.9143 - val_loss: 0.3361 - val_accuracy: 0.8786\n","Epoch 31/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.2337 - accuracy: 0.9211 - val_loss: 0.1843 - val_accuracy: 0.9431\n","Epoch 32/200\n","469/469 [==============================] - 39s 83ms/step - loss: 0.1969 - accuracy: 0.9379 - val_loss: 0.1724 - val_accuracy: 0.9486\n","Epoch 33/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.1747 - accuracy: 0.9450 - val_loss: 0.1398 - val_accuracy: 0.9589\n","Epoch 34/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.1579 - accuracy: 0.9518 - val_loss: 0.1489 - val_accuracy: 0.9561\n","Epoch 35/200\n","469/469 [==============================] - 39s 83ms/step - loss: 0.1418 - accuracy: 0.9568 - val_loss: 0.1217 - val_accuracy: 0.9648\n","Epoch 36/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.1303 - accuracy: 0.9604 - val_loss: 0.1433 - val_accuracy: 0.9564\n","Epoch 37/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.1166 - accuracy: 0.9645 - val_loss: 0.1070 - val_accuracy: 0.9680\n","Epoch 38/200\n","469/469 [==============================] - 38s 81ms/step - loss: 0.1106 - accuracy: 0.9669 - val_loss: 0.1279 - val_accuracy: 0.9604\n","Epoch 39/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0982 - accuracy: 0.9699 - val_loss: 0.1146 - val_accuracy: 0.9671\n","Epoch 40/200\n","469/469 [==============================] - 38s 81ms/step - loss: 0.0965 - accuracy: 0.9699 - val_loss: 0.0881 - val_accuracy: 0.9736\n","Epoch 41/200\n","469/469 [==============================] - 38s 81ms/step - loss: 0.0900 - accuracy: 0.9735 - val_loss: 0.0853 - val_accuracy: 0.9733\n","Epoch 42/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0852 - accuracy: 0.9742 - val_loss: 0.0876 - val_accuracy: 0.9738\n","Epoch 43/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0800 - accuracy: 0.9753 - val_loss: 0.0922 - val_accuracy: 0.9727\n","Epoch 44/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0785 - accuracy: 0.9762 - val_loss: 0.0815 - val_accuracy: 0.9770\n","Epoch 45/200\n","469/469 [==============================] - 38s 81ms/step - loss: 0.0746 - accuracy: 0.9768 - val_loss: 0.0720 - val_accuracy: 0.9797\n","Epoch 46/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0694 - accuracy: 0.9779 - val_loss: 0.0710 - val_accuracy: 0.9775\n","Epoch 47/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0668 - accuracy: 0.9796 - val_loss: 0.0711 - val_accuracy: 0.9796\n","Epoch 48/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0643 - accuracy: 0.9797 - val_loss: 0.1004 - val_accuracy: 0.9696\n","Epoch 49/200\n","469/469 [==============================] - 39s 83ms/step - loss: 0.0640 - accuracy: 0.9815 - val_loss: 0.0709 - val_accuracy: 0.9790\n","Epoch 50/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0591 - accuracy: 0.9815 - val_loss: 0.0661 - val_accuracy: 0.9803\n","Epoch 51/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0560 - accuracy: 0.9831 - val_loss: 0.0618 - val_accuracy: 0.9822\n","Epoch 52/200\n","469/469 [==============================] - 38s 81ms/step - loss: 0.0525 - accuracy: 0.9834 - val_loss: 0.0572 - val_accuracy: 0.9824\n","Epoch 53/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0508 - accuracy: 0.9842 - val_loss: 0.0713 - val_accuracy: 0.9794\n","Epoch 54/200\n","469/469 [==============================] - 38s 81ms/step - loss: 0.0539 - accuracy: 0.9836 - val_loss: 0.0577 - val_accuracy: 0.9839\n","Epoch 55/200\n","469/469 [==============================] - 38s 81ms/step - loss: 0.0470 - accuracy: 0.9852 - val_loss: 0.0636 - val_accuracy: 0.9826\n","Epoch 56/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0506 - accuracy: 0.9848 - val_loss: 0.0564 - val_accuracy: 0.9829\n","Epoch 57/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0437 - accuracy: 0.9871 - val_loss: 0.0525 - val_accuracy: 0.9846\n","Epoch 58/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0426 - accuracy: 0.9875 - val_loss: 0.0589 - val_accuracy: 0.9835\n","Epoch 59/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0402 - accuracy: 0.9873 - val_loss: 0.0651 - val_accuracy: 0.9827\n","Epoch 60/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0445 - accuracy: 0.9859 - val_loss: 0.0649 - val_accuracy: 0.9821\n","Epoch 61/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0400 - accuracy: 0.9869 - val_loss: 0.0528 - val_accuracy: 0.9851\n","Epoch 62/200\n","469/469 [==============================] - 38s 81ms/step - loss: 0.0411 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9841\n","Epoch 63/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0367 - accuracy: 0.9890 - val_loss: 0.0578 - val_accuracy: 0.9832\n","Epoch 64/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0367 - accuracy: 0.9880 - val_loss: 0.0731 - val_accuracy: 0.9779\n","Epoch 65/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0330 - accuracy: 0.9896 - val_loss: 0.0591 - val_accuracy: 0.9840\n","Epoch 66/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0342 - accuracy: 0.9891 - val_loss: 0.0493 - val_accuracy: 0.9863\n","Epoch 67/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0329 - accuracy: 0.9898 - val_loss: 0.0457 - val_accuracy: 0.9885\n","Epoch 68/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0328 - accuracy: 0.9895 - val_loss: 0.0488 - val_accuracy: 0.9864\n","Epoch 69/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0304 - accuracy: 0.9904 - val_loss: 0.0515 - val_accuracy: 0.9869\n","Epoch 70/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0397 - accuracy: 0.9882 - val_loss: 0.0544 - val_accuracy: 0.9850\n","Epoch 71/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0318 - accuracy: 0.9898 - val_loss: 0.0475 - val_accuracy: 0.9863\n","Epoch 72/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0278 - accuracy: 0.9904 - val_loss: 0.0530 - val_accuracy: 0.9858\n","Epoch 73/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0264 - accuracy: 0.9921 - val_loss: 0.0509 - val_accuracy: 0.9865\n","Epoch 74/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0261 - accuracy: 0.9913 - val_loss: 0.0501 - val_accuracy: 0.9864\n","Epoch 75/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.0522 - val_accuracy: 0.9867\n","Epoch 76/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.0531 - val_accuracy: 0.9843\n","Epoch 77/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.0622 - val_accuracy: 0.9841\n","Epoch 78/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0259 - accuracy: 0.9916 - val_loss: 0.0522 - val_accuracy: 0.9867\n","Epoch 79/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.0553 - val_accuracy: 0.9854\n","Epoch 80/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0272 - accuracy: 0.9913 - val_loss: 0.0511 - val_accuracy: 0.9853\n","Epoch 81/200\n","469/469 [==============================] - 39s 83ms/step - loss: 0.0233 - accuracy: 0.9930 - val_loss: 0.0554 - val_accuracy: 0.9848\n","Epoch 82/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.0666 - val_accuracy: 0.9826\n","Epoch 83/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 0.0692 - val_accuracy: 0.9824\n","Epoch 84/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 0.0610 - val_accuracy: 0.9840\n","Epoch 85/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0209 - accuracy: 0.9928 - val_loss: 0.0703 - val_accuracy: 0.9826\n","Epoch 86/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0544 - val_accuracy: 0.9861\n","Epoch 87/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.0530 - val_accuracy: 0.9866\n","Epoch 88/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.0550 - val_accuracy: 0.9862\n","Epoch 89/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.0572 - val_accuracy: 0.9868\n","Epoch 90/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.0699 - val_accuracy: 0.9812\n","Epoch 91/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.0565 - val_accuracy: 0.9862\n","Epoch 92/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.0536 - val_accuracy: 0.9861\n","Epoch 93/200\n","469/469 [==============================] - 39s 83ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.0556 - val_accuracy: 0.9869\n","Epoch 94/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.0576 - val_accuracy: 0.9867\n","Epoch 95/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.0649 - val_accuracy: 0.9841\n","Epoch 96/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.0621 - val_accuracy: 0.9854\n","Epoch 97/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.0492 - val_accuracy: 0.9883\n","Epoch 98/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.0569 - val_accuracy: 0.9863\n","Epoch 99/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.0577 - val_accuracy: 0.9881\n","Epoch 100/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 0.0582 - val_accuracy: 0.9863\n","Epoch 101/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.0559 - val_accuracy: 0.9872\n","Epoch 102/200\n","469/469 [==============================] - 39s 83ms/step - loss: 0.0149 - accuracy: 0.9950 - val_loss: 0.0635 - val_accuracy: 0.9840\n","Epoch 103/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0534 - val_accuracy: 0.9864\n","Epoch 104/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.0677 - val_accuracy: 0.9845\n","Epoch 105/200\n","469/469 [==============================] - 39s 83ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.0563 - val_accuracy: 0.9863\n","Epoch 106/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.0594 - val_accuracy: 0.9856\n","Epoch 107/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.0561 - val_accuracy: 0.9864\n","Epoch 108/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0506 - val_accuracy: 0.9874\n","Epoch 109/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.0668 - val_accuracy: 0.9861\n","Epoch 110/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0578 - val_accuracy: 0.9855\n","Epoch 111/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.0814 - val_accuracy: 0.9823\n","Epoch 112/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.0574 - val_accuracy: 0.9874\n","Epoch 113/200\n","469/469 [==============================] - 39s 83ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0619 - val_accuracy: 0.9851\n","Epoch 114/200\n","469/469 [==============================] - 39s 83ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.0607 - val_accuracy: 0.9872\n","Epoch 115/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.0741 - val_accuracy: 0.9839\n","Epoch 116/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.0537 - val_accuracy: 0.9884\n","Epoch 117/200\n","469/469 [==============================] - 42s 90ms/step - loss: 0.0132 - accuracy: 0.9955 - val_loss: 0.0676 - val_accuracy: 0.9858\n","Epoch 118/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0651 - val_accuracy: 0.9867\n","Epoch 119/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 0.0620 - val_accuracy: 0.9874\n","Epoch 120/200\n","469/469 [==============================] - 38s 81ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0660 - val_accuracy: 0.9856\n","Epoch 121/200\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.0702 - val_accuracy: 0.9859\n","Epoch 122/200\n","469/469 [==============================] - 38s 81ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.0602 - val_accuracy: 0.9872\n","Epoch 123/200\n","469/469 [==============================] - 42s 90ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.0619 - val_accuracy: 0.9871\n","Epoch 124/200\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0632 - val_accuracy: 0.9858\n","Epoch 125/200\n","336/469 [====================>.........] - ETA: 10s - loss: 0.0104 - accuracy: 0.9967Buffered data was truncated after reaching the output size limit."],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"H4ol13AU6v3f"},"source":["## Model pred"]},{"cell_type":"code","metadata":{"id":"7IhfXKH26fMc"},"source":["_, acc = model.evaluate(x_test,\n","                        y_test,\n","                        batch_size=batch_size,\n","                        verbose=0)\n","print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"],"execution_count":null,"outputs":[]}]}